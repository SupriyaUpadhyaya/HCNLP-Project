{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SupriyaUpadhyaya/HCNLP-Text2Sql-Project/blob/main/SQLAssist_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dependencies"
      ],
      "metadata": {
        "id": "gzVd3IltzQHr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eSvM9zX_2d3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Installs Unsloth, Xformers (Flash Attention) and all other packages!\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps \"xformers<0.0.26\" trl peft accelerate bitsandbytes\n",
        "!pip install huggingface_hub[hf_transfer]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "ikLao4ABzLp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from unsloth import FastLanguageModel\n",
        "from datasets import load_dataset, Dataset\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments"
      ],
      "metadata": {
        "id": "V7vguKqrW805"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the base model"
      ],
      "metadata": {
        "id": "CsjUk96tyrCh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmUBVEnvCDJv"
      },
      "outputs": [],
      "source": [
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/mistral-7b-bnb-4bit\",\n",
        "    \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n",
        "    \"unsloth/llama-2-7b-bnb-4bit\",\n",
        "    \"unsloth/gemma-7b-bnb-4bit\",\n",
        "    \"unsloth/gemma-7b-it-bnb-4bit\", # Instruct version of Gemma 7b\n",
        "    \"unsloth/gemma-2b-bnb-4bit\",\n",
        "    \"unsloth/gemma-2b-it-bnb-4bit\", # Instruct version of Gemma 2b\n",
        "    \"unsloth/llama-3-8b-bnb-4bit\", # [NEW] 15 Trillion token Llama-3\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
      ],
      "metadata": {
        "id": "SXd9bTZd1aaL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bZsfBuZDeCL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fcdadbc-f5fb-4e78-db20-9b00ceb53f57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2024.4 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"Data\"></a>\n",
        "### Data Prep\n"
      ],
      "metadata": {
        "id": "vITh0KVJ10qX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjY75GoYUCB8"
      },
      "outputs": [],
      "source": [
        "text_to_sql_tmpl_str = \"\"\"\\\n",
        "### Instruction:\\n{system_message}{user_message}\\n\\n### Response:\\n{response}\"\"\"\n",
        "\n",
        "text_to_sql_inference_tmpl_str = \"\"\"\\\n",
        "### Instruction:\\n{system_message}{user_message}\\n\\n### Response:\\n\"\"\"\n",
        "\n",
        "\n",
        "def _generate_prompt_sql(input, context, dialect=\"sqlite\", output=\"\"):\n",
        "    system_message = f\"\"\"You are a powerful text-to-SQL model. Your job is to answer questions about a database. You are given a question and context regarding one or more tables.\n",
        "\n",
        "You must output the SQL query that answers the question.\n",
        "\n",
        "    \"\"\"\n",
        "    user_message = f\"\"\"### Dialect:\n",
        "{dialect}\n",
        "\n",
        "### Input:\n",
        "{input}\n",
        "\n",
        "### Context:\n",
        "{context}\n",
        "\n",
        "### Response:\n",
        "\"\"\"\n",
        "    if output:\n",
        "        return text_to_sql_tmpl_str.format(\n",
        "            system_message=system_message,\n",
        "            user_message=user_message,\n",
        "            response=output,\n",
        "        )\n",
        "    else:\n",
        "        return text_to_sql_inference_tmpl_str.format(\n",
        "            system_message=system_message, user_message=user_message\n",
        "        )\n",
        "\n",
        "\n",
        "def generate_prompt(data_point):\n",
        "    full_prompt = _generate_prompt_sql(\n",
        "        data_point[\"instruction\"],\n",
        "        data_point[\"input\"],\n",
        "        dialect=\"sqlite\",\n",
        "        output=data_point[\"response\"],\n",
        "    )\n",
        "    EOS_TOKEN = tokenizer.eos_token\n",
        "    return full_prompt + EOS_TOKEN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dataset for fine-tuning\n",
        "dataset_id = \"Clinton/Text-to-sql-v1\"\n",
        "\n",
        "data = load_dataset(dataset_id, split=\"train\")\n",
        "df = data.to_pandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "273b571a15674eda901fd836f6d0349f",
            "85ce68e267a549548036a104cd0ecc27",
            "d9edd7b2fe6341c39871de9d509613a1",
            "0a25fc3fa11f4d05b414252cd6c52e3f",
            "dcebc2345cd54e799fb6b66e1fd8ce44",
            "0b30a600c8524f7c870aa25247e1ba32",
            "54e66f099a7a42859d6b62f518558d22",
            "9d2671a475b346b683a674043165cc78",
            "a6c9690dd4764812a5210b72b1ab4851",
            "53a41680078247eab52b96acef336361",
            "616dd82569724d68b28da6174cc22bef",
            "14d719f5c9ce486e9061b88813f1e53b",
            "d5d907d6472043569d599bc72e0b2984",
            "53d0cfcd7cd24df28267a61c9d5134e4",
            "9797e019e4a44c9a9429e15405f15707",
            "e14577d1388944f999eef9975e5c33cd",
            "e3883184917d4c2c94ece075ca0e6b0f",
            "08a1ceac5ee8477387ff63838b87f21d",
            "2ea01e0c1f484e3495d985235e159dfd",
            "52ee6f263b494811976b21a6bbc59992",
            "4822afeb14f547fb97478e55d1dc1480",
            "7bfcb894158647959c9f4fc999e46157",
            "0cdb63213edd44fc9eb3066585fcdd61",
            "525b425093844d57b66e12e32071e58d",
            "7c4ef6827bd944fc9f7baf2996fa1c03",
            "dc5e75fa42c24446933d2fd94c1da8d1",
            "a1088aeb1bdc43bab786cbf2afedba69",
            "0cc2a661beb240698418295030842254",
            "ed2ee3f4eb77473eb6a4e2190b408dbc",
            "ca74a52634f64e4fbf1e0044ab45bf3a",
            "c4e14c414a1a429fa98f671a6a89f030",
            "57d4cce92fa84a6d89557b3d072fa046",
            "bc9ddc2863684563b7e8111458d0b1aa"
          ]
        },
        "id": "V3bjlzFjeepS",
        "outputId": "d6adc237-b4cf-4bc0-918b-1de8ddfcfe2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/118 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "273b571a15674eda901fd836f6d0349f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/635M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14d719f5c9ce486e9061b88813f1e53b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/262208 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0cdb63213edd44fc9eb3066585fcdd61"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the chat_template_for_training function to each row in the\n",
        "# dataframe and store the result in a new \"text\" column.\n",
        "df[\"text\"] = df.apply(lambda x: generate_prompt(x), axis=1)\n",
        "\n",
        "# Convert the dataframe back to a Dataset object.\n",
        "formatted_data = Dataset.from_pandas(df)"
      ],
      "metadata": {
        "id": "dXu0awmBegx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"text\"][0]"
      ],
      "metadata": {
        "id": "AXaFsuKGEz0l",
        "outputId": "f8d0ac93-5654-4b9d-dd67-008b0b848bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'### Instruction:\\nYou are a powerful text-to-SQL model. Your job is to answer questions about a database. You are given a question and context regarding one or more tables.\\n\\nYou must output the SQL query that answers the question.\\n\\n    ### Dialect:\\nsqlite\\n\\n### Input:\\nName the home team for carlton away team\\n\\n### Context:\\nCREATE TABLE table_name_77 (\\n    home_team VARCHAR,\\n    away_team VARCHAR\\n)\\n\\n### Response:\\n\\n\\n### Response:\\nSELECT home_team FROM table_name_77 WHERE away_team = \"carlton\"<|end_of_text|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model"
      ],
      "metadata": {
        "id": "idAEIeSQ3xdS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95_Nn-89DhsL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "df333f62ea954d559381fd4ca4146aad",
            "4cac817a1b784009a6526140eb631ba7",
            "71ea401793e74de2826f99a8877cf2e6",
            "9f75c9bfd6994f33b43e5056c7b859d4",
            "450ebf71b844446a8ebff41e35fe096e",
            "fff8af58d3fb43dbac39edb0ddcae50d",
            "a72e533274c54a92b0314abc6cfa21eb",
            "268e950a6a04424cb6151f3d05e07081",
            "77c3118823aa46bfb1f18439c74de12d",
            "62c411c21ea245398ad703b812d63d97",
            "4ef16d52bba143528452ab11ed8e1876"
          ]
        },
        "outputId": "2700e704-d800-48b6-c5db-130027c73c11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/262208 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df333f62ea954d559381fd4ca4146aad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ],
      "source": [
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = formatted_data,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 100,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not torch.cuda.is_bf16_supported(),\n",
        "        bf16 = torch.cuda.is_bf16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ejIt2xSNKKp",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef1b45c2-0478-48ce-dec1-2e017fd09622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = Tesla T4. Max memory = 14.748 GB.\n",
            "5.594 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "#@title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqxqAZ7KJ4oL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d455aa1b-471c-4221-a075-5c9227cffc59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 262,208 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 8 | Total steps = 100\n",
            " \"-____-\"     Number of trainable parameters = 41,943,040\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 21:15, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.035300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.557900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.147200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.637300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.114700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.481800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.686200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.209800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.924600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.929900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.811800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.760600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.796700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.765600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.825700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.909900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.788300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.699200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.779800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.742500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.648400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.736500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.817000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.762800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.528100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.704900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.634600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.766700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.588900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.590800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.539700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.599700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.639200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.682800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.478800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.531700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.503000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.556800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.731400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.612600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.698400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.550300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.583700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.715200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.627700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.580200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.557100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.498200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.463300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.591300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.803900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.602700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.425200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.732600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.615300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.522800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.598900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.462100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.690700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.356000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.666600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.477800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.690000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.593600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.380500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.690400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.413000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.587700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.594300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.574500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.668900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.607600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.550200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.446700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.496000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.531000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.584300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.707500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.591300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.365100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.573800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.493700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.575600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.543500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.430800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.538300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.403300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.658400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.472300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.525600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.522700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.568000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.526600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.410700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.528800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.376600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.571700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.664100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.517800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.460700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCqnaKmlO1U9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dd3e570-be90-4e55-b991-4800284d6910",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "329.7482 seconds used for training.\n",
            "5.5 minutes used for training.\n",
            "Peak reserved memory = 6.311 GB.\n",
            "Peak reserved memory for training = 0.717 GB.\n",
            "Peak reserved memory % of max memory = 42.792 %.\n",
            "Peak reserved memory for training % of max memory = 4.862 %.\n"
          ]
        }
      ],
      "source": [
        "#@title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory         /max_memory*100, 3)\n",
        "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving finetuned models\n"
      ],
      "metadata": {
        "id": "uMuVrWbjAzhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"lora_model\") # Local saving\n",
        "tokenizer.save_pretrained(\"lora_model\")"
      ],
      "metadata": {
        "id": "C9xUTDYVghYk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f27ed44-066a-43ff-e1f3-595b0c56df79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('lora_model/tokenizer_config.json',\n",
              " 'lora_model/special_tokens_map.json',\n",
              " 'lora_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained_merged(\"model_16\", tokenizer, save_method = \"merged_16bit\",)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOxmm0WYcTuQ",
        "outputId": "79b4beb8-64ce-44a4-800f-d4469c8c390d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: You have 1 CPUs. Using `safe_serialization` is 10x slower.\n",
            "We shall switch to Pytorch saving, which will take 3 minutes and not 30 minutes.\n",
            "To force `safe_serialization`, set it to `None` instead.\n",
            "Unsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\n",
            "model which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\n",
            "Unsloth: Will remove a cached repo with size 5.7G\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 3.19 out of 12.67 RAM for saving.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 14/32 [00:00<00:00, 20.79it/s]We will save to Disk and not RAM now.\n",
            "100%|██████████| 32/32 [01:22<00:00,  2.58s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
            "Unsloth: Saving model_16/pytorch_model-00001-of-00004.bin...\n",
            "Unsloth: Saving model_16/pytorch_model-00002-of-00004.bin...\n",
            "Unsloth: Saving model_16/pytorch_model-00003-of-00004.bin...\n",
            "Unsloth: Saving model_16/pytorch_model-00004-of-00004.bin...\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POMky9m9jpw5",
        "outputId": "69cb0c5e-36e6-4a3a-f209-d2ff42257f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: write).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To speed up the upload, set the following variable"
      ],
      "metadata": {
        "id": "TOt_evFfydvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env HF_HUB_ENABLE_HF_TRANSFER=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UncBlHt2kmDo",
        "outputId": "47aaff12-9f30-4c96-9e67-7aaebf9ef475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: HF_HUB_ENABLE_HF_TRANSFER=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.push_to_hub_merged(\"basavaraj/text2sql-Llama3-8b\", tokenizer, save_method = \"merged_16bit\", token = \"<My_Token>\")\n",
        "!huggingface-cli upload basavaraj/text2sql-Llama3-8b model_16 ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjIlN6wPjymi",
        "outputId": "69e36475-2aac-4207-dea9-de72840fc43e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  0% 0/4 [00:00<?, ?it/s]\n",
            "pytorch_model-00001-of-00004.bin:   0% 0.00/4.98G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   0% 16.0M/4.98G [00:12<1:04:16, 1.29MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   1% 32.0M/4.98G [00:14<32:22, 2.55MB/s]  \u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   1% 48.0M/4.98G [00:15<20:00, 4.10MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   1% 64.0M/4.98G [00:15<12:20, 6.63MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   2% 80.0M/4.98G [00:15<08:04, 10.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   2% 96.0M/4.98G [00:15<05:39, 14.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   3% 128M/4.98G [00:16<03:12, 25.2MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   3% 160M/4.98G [00:16<02:07, 37.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   4% 176M/4.98G [00:16<02:10, 36.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   5% 224M/4.98G [00:17<01:13, 64.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   5% 256M/4.98G [00:17<01:01, 77.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   6% 304M/4.98G [00:17<00:43, 108MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   7% 368M/4.98G [00:17<00:27, 168MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   9% 432M/4.98G [00:17<00:19, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  10% 480M/4.98G [00:17<00:18, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  11% 528M/4.98G [00:18<00:15, 283MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  12% 608M/4.98G [00:18<00:11, 385MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  14% 672M/4.98G [00:18<00:10, 403MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  15% 736M/4.98G [00:18<00:10, 409MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  16% 800M/4.98G [00:18<00:09, 440MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  17% 864M/4.98G [00:18<00:10, 382MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  19% 928M/4.98G [00:18<00:11, 367MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  21% 1.04G/4.98G [00:19<00:08, 482MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  22% 1.10G/4.98G [00:19<00:08, 450MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  23% 1.17G/4.98G [00:19<00:08, 467MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  25% 1.23G/4.98G [00:19<00:08, 436MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  26% 1.28G/4.98G [00:19<00:08, 430MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  28% 1.38G/4.98G [00:19<00:06, 530MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  29% 1.44G/4.98G [00:19<00:06, 519MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  30% 1.50G/4.98G [00:20<00:06, 507MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  32% 1.57G/4.98G [00:20<00:11, 292MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  32% 1.62G/4.98G [00:20<00:12, 263MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  33% 1.66G/4.98G [00:20<00:12, 275MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  34% 1.71G/4.98G [00:21<00:14, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  35% 1.76G/4.98G [00:21<00:13, 244MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  36% 1.81G/4.98G [00:21<00:11, 277MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  37% 1.86G/4.98G [00:21<00:10, 295MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  38% 1.90G/4.98G [00:21<00:12, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  39% 1.94G/4.98G [00:22<00:17, 169MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  40% 1.97G/4.98G [00:22<00:16, 178MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  40% 2.00G/4.98G [00:22<00:17, 170MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  41% 2.03G/4.98G [00:23<00:32, 91.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  41% 2.06G/4.98G [00:25<01:05, 44.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  42% 2.08G/4.98G [00:29<02:54, 16.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  42% 2.10G/4.98G [00:31<03:29, 13.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  42% 2.11G/4.98G [00:34<04:33, 10.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  43% 2.13G/4.98G [00:34<03:42, 12.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  43% 2.16G/4.98G [00:34<02:21, 19.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  44% 2.18G/4.98G [00:35<02:10, 21.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  44% 2.21G/4.98G [00:35<01:27, 31.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  45% 2.24G/4.98G [00:35<01:09, 39.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  45% 2.26G/4.98G [00:36<01:00, 45.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  46% 2.29G/4.98G [00:36<00:43, 61.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  46% 2.30G/4.98G [00:36<00:42, 62.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  47% 2.34G/4.98G [00:36<00:30, 88.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  47% 2.35G/4.98G [00:36<00:30, 84.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  48% 2.37G/4.98G [00:36<00:28, 92.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  49% 2.43G/4.98G [00:37<00:17, 146MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  50% 2.48G/4.98G [00:37<00:12, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  51% 2.53G/4.98G [00:37<00:13, 184MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  51% 2.56G/4.98G [00:37<00:11, 203MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  52% 2.59G/4.98G [00:38<00:14, 162MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  53% 2.66G/4.98G [00:38<00:09, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  54% 2.70G/4.98G [00:38<00:08, 270MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  55% 2.75G/4.98G [00:38<00:08, 267MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  57% 2.82G/4.98G [00:38<00:06, 341MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  58% 2.86G/4.98G [00:38<00:07, 298MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  59% 2.91G/4.98G [00:39<00:09, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  59% 2.94G/4.98G [00:39<00:10, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  60% 2.98G/4.98G [00:39<00:10, 184MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  60% 3.01G/4.98G [00:39<00:10, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  61% 3.06G/4.98G [00:39<00:08, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  62% 3.10G/4.98G [00:39<00:06, 274MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  63% 3.15G/4.98G [00:40<00:06, 292MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  64% 3.20G/4.98G [00:40<00:06, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  65% 3.25G/4.98G [00:40<00:07, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  67% 3.33G/4.98G [00:40<00:04, 338MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  68% 3.38G/4.98G [00:40<00:04, 332MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  69% 3.44G/4.98G [00:40<00:03, 395MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  71% 3.54G/4.98G [00:41<00:03, 432MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  72% 3.58G/4.98G [00:41<00:03, 416MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  73% 3.65G/4.98G [00:41<00:02, 450MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  74% 3.70G/4.98G [00:41<00:03, 387MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  75% 3.74G/4.98G [00:41<00:03, 330MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  76% 3.79G/4.98G [00:41<00:03, 354MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  77% 3.84G/4.98G [00:42<00:03, 323MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  78% 3.89G/4.98G [00:42<00:03, 349MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  79% 3.94G/4.98G [00:42<00:04, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  80% 3.97G/4.98G [00:42<00:04, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  80% 4.00G/4.98G [00:42<00:05, 174MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  81% 4.03G/4.98G [00:43<00:07, 121MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  82% 4.06G/4.98G [00:43<00:07, 119MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  82% 4.10G/4.98G [00:44<00:07, 115MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  83% 4.11G/4.98G [00:44<00:10, 84.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  83% 4.13G/4.98G [00:45<00:15, 55.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  83% 4.14G/4.98G [00:45<00:17, 49.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  84% 4.16G/4.98G [00:45<00:15, 52.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  84% 4.18G/4.98G [00:46<00:17, 46.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  84% 4.19G/4.98G [00:46<00:14, 53.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  85% 4.22G/4.98G [00:46<00:10, 73.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  85% 4.24G/4.98G [00:46<00:09, 74.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  86% 4.26G/4.98G [00:47<00:08, 84.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  86% 4.29G/4.98G [00:47<00:05, 119MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  87% 4.32G/4.98G [00:47<00:04, 143MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  87% 4.35G/4.98G [00:47<00:04, 152MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  89% 4.45G/4.98G [00:47<00:01, 296MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  90% 4.50G/4.98G [00:47<00:01, 302MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  92% 4.58G/4.98G [00:47<00:01, 379MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  94% 4.69G/4.98G [00:48<00:00, 537MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  95% 4.75G/4.98G [00:48<00:00, 527MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  98% 4.90G/4.98G [00:48<00:00, 733MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin: 4.99GB [00:48, 103MB/s]\n",
            " 25% 1/4 [00:48<02:26, 48.93s/it]\n",
            "pytorch_model-00002-of-00004.bin:   0% 0.00/5.00G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   0% 16.0M/5.00G [00:15<1:22:53, 1.00MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   1% 32.0M/5.00G [00:16<36:11, 2.29MB/s]  \u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   1% 64.0M/5.00G [00:17<14:11, 5.79MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   2% 80.0M/5.00G [00:17<10:05, 8.12MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   2% 96.0M/5.00G [00:17<07:33, 10.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   2% 112M/5.00G [00:17<05:33, 14.7MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   3% 144M/5.00G [00:18<03:04, 26.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   4% 176M/5.00G [00:18<02:03, 39.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   4% 208M/5.00G [00:18<01:26, 55.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   5% 240M/5.00G [00:18<01:09, 68.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   6% 288M/5.00G [00:18<00:44, 106MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   6% 320M/5.00G [00:18<00:35, 130MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   7% 352M/5.00G [00:19<00:30, 153MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   8% 384M/5.00G [00:19<00:26, 175MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   9% 464M/5.00G [00:19<00:17, 262MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  10% 512M/5.00G [00:19<00:17, 264MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  11% 560M/5.00G [00:19<00:22, 196MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  12% 592M/5.00G [00:19<00:21, 207MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  13% 656M/5.00G [00:20<00:16, 269MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  15% 736M/5.00G [00:20<00:11, 356MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  17% 848M/5.00G [00:20<00:08, 483MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  18% 912M/5.00G [00:20<00:12, 318MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  19% 960M/5.00G [00:20<00:12, 323MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  20% 1.01G/5.00G [00:21<00:11, 347MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  22% 1.10G/5.00G [00:21<00:09, 415MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  24% 1.20G/5.00G [00:21<00:08, 427MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  25% 1.26G/5.00G [00:21<00:08, 435MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  27% 1.34G/5.00G [00:21<00:07, 485MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  28% 1.42G/5.00G [00:21<00:06, 524MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  30% 1.49G/5.00G [00:22<00:08, 391MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  31% 1.55G/5.00G [00:22<00:08, 428MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  32% 1.62G/5.00G [00:22<00:08, 415MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  34% 1.68G/5.00G [00:22<00:07, 443MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  35% 1.74G/5.00G [00:22<00:07, 444MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  36% 1.81G/5.00G [00:22<00:07, 452MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  37% 1.86G/5.00G [00:23<00:10, 304MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  38% 1.90G/5.00G [00:23<00:12, 255MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  39% 1.94G/5.00G [00:24<00:29, 102MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  39% 1.97G/5.00G [00:24<00:32, 92.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  40% 2.00G/5.00G [00:25<00:30, 99.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  41% 2.03G/5.00G [00:25<00:32, 90.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  41% 2.05G/5.00G [00:28<01:46, 27.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  41% 2.06G/5.00G [00:34<04:44, 10.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  42% 2.08G/5.00G [00:35<04:26, 10.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  42% 2.10G/5.00G [00:36<04:04, 11.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  42% 2.11G/5.00G [00:36<03:11, 15.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  43% 2.14G/5.00G [00:36<01:56, 24.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  44% 2.19G/5.00G [00:37<01:09, 40.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  44% 2.22G/5.00G [00:37<00:52, 52.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  45% 2.27G/5.00G [00:37<00:35, 76.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  46% 2.30G/5.00G [00:37<00:28, 94.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  47% 2.34G/5.00G [00:38<00:30, 86.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  47% 2.35G/5.00G [00:38<00:29, 89.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  48% 2.38G/5.00G [00:38<00:30, 86.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  48% 2.40G/5.00G [00:38<00:30, 85.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  48% 2.42G/5.00G [00:38<00:28, 89.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  49% 2.45G/5.00G [00:39<00:23, 107MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  50% 2.48G/5.00G [00:39<00:19, 132MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  50% 2.51G/5.00G [00:39<00:16, 147MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  51% 2.54G/5.00G [00:39<00:14, 169MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  52% 2.58G/5.00G [00:39<00:15, 155MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  53% 2.66G/5.00G [00:39<00:09, 247MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  54% 2.69G/5.00G [00:40<00:11, 201MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  54% 2.72G/5.00G [00:40<00:11, 195MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  55% 2.77G/5.00G [00:40<00:09, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  57% 2.83G/5.00G [00:40<00:08, 270MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  57% 2.86G/5.00G [00:40<00:07, 271MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  58% 2.90G/5.00G [00:40<00:07, 281MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  59% 2.93G/5.00G [00:41<00:07, 277MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  60% 2.98G/5.00G [00:41<00:06, 301MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  60% 3.01G/5.00G [00:41<00:07, 262MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  62% 3.09G/5.00G [00:41<00:06, 309MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  63% 3.15G/5.00G [00:41<00:05, 333MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  64% 3.20G/5.00G [00:41<00:05, 353MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  65% 3.26G/5.00G [00:41<00:04, 373MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  66% 3.31G/5.00G [00:42<00:05, 318MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  68% 3.39G/5.00G [00:42<00:04, 376MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  70% 3.49G/5.00G [00:42<00:03, 494MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  71% 3.55G/5.00G [00:42<00:02, 483MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  72% 3.62G/5.00G [00:42<00:03, 411MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  73% 3.66G/5.00G [00:42<00:03, 373MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  74% 3.71G/5.00G [00:43<00:03, 342MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  75% 3.76G/5.00G [00:43<00:03, 353MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  76% 3.81G/5.00G [00:43<00:03, 316MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  77% 3.87G/5.00G [00:43<00:03, 325MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  78% 3.92G/5.00G [00:43<00:03, 288MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  79% 3.97G/5.00G [00:43<00:03, 315MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  80% 4.02G/5.00G [00:44<00:04, 245MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  81% 4.05G/5.00G [00:44<00:05, 168MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  82% 4.08G/5.00G [00:45<00:08, 113MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  82% 4.11G/5.00G [00:46<00:13, 65.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  83% 4.13G/5.00G [00:47<00:24, 35.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  83% 4.16G/5.00G [00:48<00:19, 44.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  84% 4.19G/5.00G [00:48<00:14, 54.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  84% 4.22G/5.00G [00:48<00:10, 71.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  85% 4.26G/5.00G [00:48<00:08, 87.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  86% 4.29G/5.00G [00:49<00:07, 98.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  86% 4.32G/5.00G [00:49<00:05, 122MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  87% 4.35G/5.00G [00:49<00:04, 148MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  88% 4.40G/5.00G [00:49<00:03, 180MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  90% 4.50G/5.00G [00:49<00:01, 305MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  91% 4.54G/5.00G [00:49<00:01, 332MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  92% 4.61G/5.00G [00:49<00:01, 381MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  94% 4.70G/5.00G [00:49<00:00, 506MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  97% 4.85G/5.00G [00:50<00:00, 711MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin: 5.01GB [00:50, 99.0MB/s]               \n",
            " 50% 2/4 [01:39<01:40, 50.06s/it]\n",
            "pytorch_model-00003-of-00004.bin:   0% 0.00/4.92G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   0% 16.0M/4.92G [00:16<1:22:03, 995kB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   1% 32.0M/4.92G [00:16<35:12, 2.31MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   1% 48.0M/4.92G [00:16<19:34, 4.15MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   2% 96.0M/4.92G [00:17<06:48, 11.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   3% 128M/4.92G [00:17<04:32, 17.6MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   3% 160M/4.92G [00:17<03:03, 25.9MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   4% 176M/4.92G [00:18<02:52, 27.5MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   4% 192M/4.92G [00:18<02:23, 32.9MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   5% 256M/4.92G [00:18<01:09, 67.3MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   7% 320M/4.92G [00:18<00:41, 111MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   7% 352M/4.92G [00:18<00:36, 125MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   8% 384M/4.92G [00:18<00:34, 132MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   9% 448M/4.92G [00:18<00:23, 190MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  10% 480M/4.92G [00:19<00:21, 204MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  10% 512M/4.92G [00:19<00:21, 206MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  12% 592M/4.92G [00:19<00:17, 253MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  13% 656M/4.92G [00:19<00:14, 294MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  14% 704M/4.92G [00:19<00:13, 316MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  15% 752M/4.92G [00:20<00:15, 269MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  18% 880M/4.92G [00:20<00:09, 412MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  19% 928M/4.92G [00:20<00:10, 380MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  21% 1.01G/4.92G [00:20<00:08, 462MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  22% 1.10G/4.92G [00:20<00:07, 491MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  24% 1.17G/4.92G [00:20<00:07, 487MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  25% 1.23G/4.92G [00:20<00:07, 492MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  27% 1.33G/4.92G [00:20<00:06, 588MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  28% 1.39G/4.92G [00:21<00:06, 580MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  30% 1.46G/4.92G [00:21<00:07, 441MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  31% 1.52G/4.92G [00:21<00:12, 280MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  32% 1.57G/4.92G [00:21<00:11, 304MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  33% 1.62G/4.92G [00:22<00:11, 283MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  35% 1.70G/4.92G [00:22<00:08, 358MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  36% 1.78G/4.92G [00:22<00:08, 382MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  37% 1.84G/4.92G [00:22<00:08, 379MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  38% 1.89G/4.92G [00:22<00:09, 327MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  39% 1.94G/4.92G [00:23<00:11, 262MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  40% 1.97G/4.92G [00:24<00:25, 114MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  41% 2.00G/4.92G [00:24<00:26, 112MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  41% 2.03G/4.92G [00:24<00:29, 96.2MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  42% 2.05G/4.92G [00:26<01:02, 45.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  42% 2.06G/4.92G [00:34<04:58, 9.56MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  42% 2.08G/4.92G [00:36<05:10, 9.13MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  43% 2.10G/4.92G [00:36<04:07, 11.4MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  43% 2.13G/4.92G [00:36<02:38, 17.6MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  44% 2.18G/4.92G [00:36<01:28, 30.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  45% 2.21G/4.92G [00:37<01:05, 41.2MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  46% 2.24G/4.92G [00:37<00:54, 48.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  46% 2.27G/4.92G [00:37<00:45, 58.2MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  47% 2.29G/4.92G [00:37<00:41, 63.4MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  48% 2.34G/4.92G [00:38<00:27, 94.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  48% 2.37G/4.92G [00:38<00:28, 88.5MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  49% 2.40G/4.92G [00:38<00:22, 111MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  50% 2.45G/4.92G [00:38<00:15, 156MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  50% 2.48G/4.92G [00:38<00:13, 177MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  52% 2.56G/4.92G [00:39<00:08, 282MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  53% 2.62G/4.92G [00:39<00:07, 311MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  54% 2.67G/4.92G [00:39<00:07, 289MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  56% 2.74G/4.92G [00:39<00:06, 319MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  57% 2.80G/4.92G [00:39<00:06, 314MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  59% 2.88G/4.92G [00:39<00:05, 400MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  60% 2.94G/4.92G [00:40<00:05, 364MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  61% 2.99G/4.92G [00:40<00:05, 350MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  62% 3.04G/4.92G [00:40<00:05, 366MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  63% 3.09G/4.92G [00:40<00:05, 359MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  64% 3.15G/4.92G [00:40<00:04, 407MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  65% 3.22G/4.92G [00:40<00:04, 406MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  66% 3.26G/4.92G [00:40<00:04, 349MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  67% 3.31G/4.92G [00:41<00:04, 371MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  69% 3.41G/4.92G [00:41<00:03, 493MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  71% 3.47G/4.92G [00:41<00:02, 486MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  72% 3.54G/4.92G [00:41<00:03, 416MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  74% 3.62G/4.92G [00:41<00:02, 485MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  75% 3.68G/4.92G [00:41<00:02, 423MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  76% 3.73G/4.92G [00:42<00:03, 326MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  77% 3.78G/4.92G [00:42<00:03, 299MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  78% 3.82G/4.92G [00:42<00:03, 324MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  79% 3.87G/4.92G [00:42<00:03, 338MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  80% 3.92G/4.92G [00:42<00:03, 278MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  81% 3.97G/4.92G [00:42<00:03, 310MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  82% 4.02G/4.92G [00:43<00:03, 229MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  82% 4.05G/4.92G [00:43<00:04, 175MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  83% 4.08G/4.92G [00:43<00:04, 193MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  84% 4.11G/4.92G [00:44<00:08, 89.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  84% 4.14G/4.92G [00:47<00:26, 29.7MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  85% 4.18G/4.92G [00:47<00:19, 38.3MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  86% 4.24G/4.92G [00:48<00:10, 63.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  87% 4.27G/4.92G [00:48<00:08, 74.3MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  88% 4.30G/4.92G [00:48<00:06, 91.0MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  89% 4.35G/4.92G [00:48<00:04, 127MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  89% 4.38G/4.92G [00:48<00:03, 147MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  91% 4.50G/4.92G [00:48<00:01, 274MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  94% 4.64G/4.92G [00:48<00:00, 457MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  98% 4.82G/4.92G [00:48<00:00, 691MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin: 4.93GB [00:49, 100MB/s]\n",
            " 75% 3/4 [02:29<00:49, 49.81s/it]\n",
            "pytorch_model-00004-of-00004.bin:   0% 0.00/1.17G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:   1% 16.0M/1.17G [00:00<01:01, 18.7MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:   3% 32.0M/1.17G [00:07<04:59, 3.79MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:   5% 64.0M/1.17G [00:07<01:54, 9.62MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:   7% 80.0M/1.17G [00:07<01:20, 13.5MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:   8% 96.0M/1.17G [00:07<00:57, 18.5MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  10% 112M/1.17G [00:08<00:42, 24.6MB/s] \u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  12% 144M/1.17G [00:08<00:30, 33.4MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  14% 160M/1.17G [00:08<00:25, 39.7MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  16% 192M/1.17G [00:08<00:15, 61.8MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  22% 256M/1.17G [00:09<00:08, 113MB/s] \u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  25% 288M/1.17G [00:09<00:07, 119MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  27% 320M/1.17G [00:10<00:09, 86.8MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  30% 352M/1.17G [00:10<00:09, 86.8MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  33% 384M/1.17G [00:10<00:07, 109MB/s] \u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  36% 416M/1.17G [00:10<00:06, 115MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  38% 448M/1.17G [00:11<00:06, 112MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  44% 512M/1.17G [00:11<00:03, 178MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  48% 560M/1.17G [00:11<00:03, 199MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  58% 672M/1.17G [00:11<00:01, 343MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  64% 752M/1.17G [00:11<00:00, 426MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  77% 896M/1.17G [00:11<00:00, 625MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  86% 1.01G/1.17G [00:11<00:00, 711MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin: 1.18GB [00:12, 97.5MB/s]               \n",
            "100% 4/4 [02:41<00:00, 40.42s/it]\n",
            "https://huggingface.co/basavaraj/text2sql-Llama3-8b/tree/main/.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "273b571a15674eda901fd836f6d0349f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85ce68e267a549548036a104cd0ecc27",
              "IPY_MODEL_d9edd7b2fe6341c39871de9d509613a1",
              "IPY_MODEL_0a25fc3fa11f4d05b414252cd6c52e3f"
            ],
            "layout": "IPY_MODEL_dcebc2345cd54e799fb6b66e1fd8ce44"
          }
        },
        "85ce68e267a549548036a104cd0ecc27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b30a600c8524f7c870aa25247e1ba32",
            "placeholder": "​",
            "style": "IPY_MODEL_54e66f099a7a42859d6b62f518558d22",
            "value": "Downloading readme: 100%"
          }
        },
        "d9edd7b2fe6341c39871de9d509613a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d2671a475b346b683a674043165cc78",
            "max": 118,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6c9690dd4764812a5210b72b1ab4851",
            "value": 118
          }
        },
        "0a25fc3fa11f4d05b414252cd6c52e3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53a41680078247eab52b96acef336361",
            "placeholder": "​",
            "style": "IPY_MODEL_616dd82569724d68b28da6174cc22bef",
            "value": " 118/118 [00:00&lt;00:00, 7.53kB/s]"
          }
        },
        "dcebc2345cd54e799fb6b66e1fd8ce44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b30a600c8524f7c870aa25247e1ba32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54e66f099a7a42859d6b62f518558d22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d2671a475b346b683a674043165cc78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6c9690dd4764812a5210b72b1ab4851": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53a41680078247eab52b96acef336361": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "616dd82569724d68b28da6174cc22bef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14d719f5c9ce486e9061b88813f1e53b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5d907d6472043569d599bc72e0b2984",
              "IPY_MODEL_53d0cfcd7cd24df28267a61c9d5134e4",
              "IPY_MODEL_9797e019e4a44c9a9429e15405f15707"
            ],
            "layout": "IPY_MODEL_e14577d1388944f999eef9975e5c33cd"
          }
        },
        "d5d907d6472043569d599bc72e0b2984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3883184917d4c2c94ece075ca0e6b0f",
            "placeholder": "​",
            "style": "IPY_MODEL_08a1ceac5ee8477387ff63838b87f21d",
            "value": "Downloading data: 100%"
          }
        },
        "53d0cfcd7cd24df28267a61c9d5134e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ea01e0c1f484e3495d985235e159dfd",
            "max": 634820326,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52ee6f263b494811976b21a6bbc59992",
            "value": 634820326
          }
        },
        "9797e019e4a44c9a9429e15405f15707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4822afeb14f547fb97478e55d1dc1480",
            "placeholder": "​",
            "style": "IPY_MODEL_7bfcb894158647959c9f4fc999e46157",
            "value": " 635M/635M [00:04&lt;00:00, 152MB/s]"
          }
        },
        "e14577d1388944f999eef9975e5c33cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3883184917d4c2c94ece075ca0e6b0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08a1ceac5ee8477387ff63838b87f21d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ea01e0c1f484e3495d985235e159dfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52ee6f263b494811976b21a6bbc59992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4822afeb14f547fb97478e55d1dc1480": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bfcb894158647959c9f4fc999e46157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cdb63213edd44fc9eb3066585fcdd61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_525b425093844d57b66e12e32071e58d",
              "IPY_MODEL_7c4ef6827bd944fc9f7baf2996fa1c03",
              "IPY_MODEL_dc5e75fa42c24446933d2fd94c1da8d1"
            ],
            "layout": "IPY_MODEL_a1088aeb1bdc43bab786cbf2afedba69"
          }
        },
        "525b425093844d57b66e12e32071e58d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cc2a661beb240698418295030842254",
            "placeholder": "​",
            "style": "IPY_MODEL_ed2ee3f4eb77473eb6a4e2190b408dbc",
            "value": "Generating train split: 100%"
          }
        },
        "7c4ef6827bd944fc9f7baf2996fa1c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca74a52634f64e4fbf1e0044ab45bf3a",
            "max": 262208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4e14c414a1a429fa98f671a6a89f030",
            "value": 262208
          }
        },
        "dc5e75fa42c24446933d2fd94c1da8d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57d4cce92fa84a6d89557b3d072fa046",
            "placeholder": "​",
            "style": "IPY_MODEL_bc9ddc2863684563b7e8111458d0b1aa",
            "value": " 262208/262208 [00:07&lt;00:00, 9737.67 examples/s]"
          }
        },
        "a1088aeb1bdc43bab786cbf2afedba69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cc2a661beb240698418295030842254": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed2ee3f4eb77473eb6a4e2190b408dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca74a52634f64e4fbf1e0044ab45bf3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4e14c414a1a429fa98f671a6a89f030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57d4cce92fa84a6d89557b3d072fa046": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc9ddc2863684563b7e8111458d0b1aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df333f62ea954d559381fd4ca4146aad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cac817a1b784009a6526140eb631ba7",
              "IPY_MODEL_71ea401793e74de2826f99a8877cf2e6",
              "IPY_MODEL_9f75c9bfd6994f33b43e5056c7b859d4"
            ],
            "layout": "IPY_MODEL_450ebf71b844446a8ebff41e35fe096e"
          }
        },
        "4cac817a1b784009a6526140eb631ba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fff8af58d3fb43dbac39edb0ddcae50d",
            "placeholder": "​",
            "style": "IPY_MODEL_a72e533274c54a92b0314abc6cfa21eb",
            "value": "Map (num_proc=2): 100%"
          }
        },
        "71ea401793e74de2826f99a8877cf2e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_268e950a6a04424cb6151f3d05e07081",
            "max": 262208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77c3118823aa46bfb1f18439c74de12d",
            "value": 262208
          }
        },
        "9f75c9bfd6994f33b43e5056c7b859d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62c411c21ea245398ad703b812d63d97",
            "placeholder": "​",
            "style": "IPY_MODEL_4ef16d52bba143528452ab11ed8e1876",
            "value": " 262208/262208 [04:42&lt;00:00, 768.00 examples/s]"
          }
        },
        "450ebf71b844446a8ebff41e35fe096e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fff8af58d3fb43dbac39edb0ddcae50d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a72e533274c54a92b0314abc6cfa21eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "268e950a6a04424cb6151f3d05e07081": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77c3118823aa46bfb1f18439c74de12d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "62c411c21ea245398ad703b812d63d97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ef16d52bba143528452ab11ed8e1876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}